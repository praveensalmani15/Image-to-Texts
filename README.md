# Image-to-Texts
We will be extracting the text from images
Hereâ€™s a sample README file for your GitHub repository:

---

# Image to Text Annotation using Google Gemini

This project is an **Image to Text Application** built with Streamlit and Google Gemini's generative AI capabilities. The app allows users to upload an image, input a prompt, and get a text annotation generated by the AI model.

## Features

- Upload images in JPG, JPEG, or PNG formats.
- Input a custom prompt to guide the annotation.
- Generates text annotations using Google Gemini (model: gemini-1.5-flash).
- Displays the uploaded image along with the generated text on the same page.

## Installation

To run this application locally, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/image-to-text-annotation.git
   cd image-to-text-annotation
   ```

2. Create a virtual environment and activate it:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. Install the required dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Set up your Google API key in a `.env` file:
   ```
   GOOGLE-API-KEY=your_google_api_key
   ```

## Usage

To run the app, use the following command:
```bash
streamlit run app.py
```

### Input and Upload:
- **Input Prompt**: You can optionally provide a text prompt to guide the AI's response.
- **Image Upload**: Upload an image in one of the supported formats (JPG, JPEG, PNG).

### Output:
- The uploaded image will be displayed.
- A text annotation based on the image and the provided prompt will be generated by Google Gemini and displayed below the image.

## Requirements

- Python 3.7+
- Streamlit
- Pillow (for image processing)
- Google Generative AI (Google Gemini)
- dotenv (for managing environment variables)

You can install the dependencies using the command:
```bash
pip install streamlit google-generativeai python-dotenv Pillow
```

## How it Works

1. The app allows users to upload an image and input a prompt.
2. Upon submitting, the app sends the image and the prompt to Google Gemini's model.
3. The model generates a text annotation which is then displayed on the app.

## Example

1. Upload an image (e.g., a landscape).
2. Input a prompt like "Describe the scene in the image."
3. The app generates a text annotation such as: "A serene landscape with mountains in the background and a flowing river."

## License

This project is licensed under the MIT License.

## Contact

For any inquiries or feedback, feel free to reach out.

